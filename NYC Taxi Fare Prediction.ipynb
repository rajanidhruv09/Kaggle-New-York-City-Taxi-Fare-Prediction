{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\", \"passenger_count\", \"pickup_day\", \n",
    "            \"pickup_hour\",\"pickup_day_of_week\", \"pickup_month\", \"pickup_year\", \"is_pickup_JFK\", \"is_dropoff_JFK\", \n",
    "            \"is_pickup_EWR\", \"is_dropoff_EWR\", \"is_pickup_la_guardia\", \"is_dropoff_la_guardia\", \"trip_distance\"]\n",
    "target = [\"fare_amount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"C:/Users/dhruv/Machine Learning/cleaned_train_data.csv\", usecols = features)\n",
    "y = pd.read_csv(\"C:/Users/dhruv/Machine Learning/cleaned_train_data.csv\", usecols = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE of Validation data:  9.600321642864396\n"
     ]
    }
   ],
   "source": [
    "#Creating a baseline prediction and calculating RMSE\n",
    "\n",
    "avg_fare = round(np.mean(y_train),2)\n",
    "baseline_pred=np.repeat(avg_fare, y_test.shape[0])\n",
    "baseline_rmse=np.sqrt(mean_squared_error(baseline_pred, y_test))\n",
    "print(\"Baseline RMSE of Validation data: \", baseline_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE for Linear Regression is  4.955841583221551\n",
      "Train RMSE for Linear Regression is  4.966887194386981\n",
      "Variance for Linear Regression is  0.01104561116542957\n"
     ]
    }
   ],
   "source": [
    "#Creating a LinearRegression model and calculating the RMSE of the predictions\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "y_pred = np.round(lm.predict(X_test), 2)\n",
    "lm_rmse=np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "lm_train_rmse = np.sqrt(mean_squared_error(lm.predict(X_train), y_train))\n",
    "lm_variance=abs(lm_train_rmse - lm_rmse)\n",
    "print(\"Test RMSE for Linear Regression is \", lm_rmse)\n",
    "print(\"Train RMSE for Linear Regression is \", lm_train_rmse)\n",
    "print(\"Variance for Linear Regression is \", lm_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dhruv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Light GBM is  3.5747546735970523\n"
     ]
    }
   ],
   "source": [
    "#Creating a LightGBM Model for better prediction and a better RMSE value\n",
    "\n",
    "train_data=lgb.Dataset(X_train,label=y_train)\n",
    "param = {'num_leaves':31, 'num_trees':5000,'objective':'regression'}\n",
    "param['metric'] = 'l2_root'\n",
    "lgb_bst=lgb.train(param,train_data,100)\n",
    "lgb_pred = lgb_bst.predict(X_test)\n",
    "lgb_rmse=np.sqrt(mean_squared_error(lgb_pred, y_test))\n",
    "print(\"RMSE for Light GBM is \",lgb_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dhruv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\engine.py:430: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tcv_agg's rmse: 4.29848 + 0.0991737\n",
      "[40]\tcv_agg's rmse: 3.98245 + 0.0997185\n",
      "[60]\tcv_agg's rmse: 3.8953 + 0.101485\n",
      "[80]\tcv_agg's rmse: 3.85209 + 0.100272\n",
      "[100]\tcv_agg's rmse: 3.81881 + 0.100226\n",
      "[120]\tcv_agg's rmse: 3.79493 + 0.100373\n",
      "[140]\tcv_agg's rmse: 3.77628 + 0.10098\n",
      "[160]\tcv_agg's rmse: 3.7603 + 0.100003\n",
      "[180]\tcv_agg's rmse: 3.74858 + 0.100658\n",
      "[200]\tcv_agg's rmse: 3.73797 + 0.100502\n",
      "[220]\tcv_agg's rmse: 3.72853 + 0.101448\n",
      "[240]\tcv_agg's rmse: 3.72028 + 0.100375\n",
      "[260]\tcv_agg's rmse: 3.7119 + 0.10068\n",
      "[280]\tcv_agg's rmse: 3.70528 + 0.10144\n",
      "[300]\tcv_agg's rmse: 3.69949 + 0.100944\n",
      "[320]\tcv_agg's rmse: 3.69379 + 0.101617\n",
      "[340]\tcv_agg's rmse: 3.6877 + 0.102821\n",
      "[360]\tcv_agg's rmse: 3.68307 + 0.103489\n",
      "[380]\tcv_agg's rmse: 3.67904 + 0.103507\n",
      "[400]\tcv_agg's rmse: 3.67511 + 0.103894\n",
      "[420]\tcv_agg's rmse: 3.67149 + 0.103958\n",
      "[440]\tcv_agg's rmse: 3.66822 + 0.103971\n",
      "[460]\tcv_agg's rmse: 3.66502 + 0.104768\n",
      "[480]\tcv_agg's rmse: 3.66187 + 0.105182\n",
      "[500]\tcv_agg's rmse: 3.65901 + 0.105249\n",
      "[520]\tcv_agg's rmse: 3.65653 + 0.105304\n",
      "[540]\tcv_agg's rmse: 3.6546 + 0.105425\n",
      "[560]\tcv_agg's rmse: 3.65232 + 0.105639\n",
      "[580]\tcv_agg's rmse: 3.65019 + 0.10571\n",
      "[600]\tcv_agg's rmse: 3.64859 + 0.105662\n",
      "[620]\tcv_agg's rmse: 3.64673 + 0.10528\n",
      "[640]\tcv_agg's rmse: 3.6449 + 0.105342\n",
      "[660]\tcv_agg's rmse: 3.64319 + 0.105367\n",
      "[680]\tcv_agg's rmse: 3.64132 + 0.105156\n",
      "[700]\tcv_agg's rmse: 3.63937 + 0.105097\n",
      "[720]\tcv_agg's rmse: 3.63786 + 0.10459\n",
      "[740]\tcv_agg's rmse: 3.63663 + 0.104109\n",
      "[760]\tcv_agg's rmse: 3.63549 + 0.10416\n",
      "[780]\tcv_agg's rmse: 3.63435 + 0.104167\n",
      "[800]\tcv_agg's rmse: 3.63278 + 0.104186\n",
      "[820]\tcv_agg's rmse: 3.63174 + 0.104229\n",
      "[840]\tcv_agg's rmse: 3.63103 + 0.104022\n",
      "[860]\tcv_agg's rmse: 3.63006 + 0.103933\n",
      "[880]\tcv_agg's rmse: 3.62893 + 0.103902\n",
      "[900]\tcv_agg's rmse: 3.62815 + 0.10392\n",
      "[920]\tcv_agg's rmse: 3.62714 + 0.103738\n",
      "[940]\tcv_agg's rmse: 3.62657 + 0.103905\n",
      "[960]\tcv_agg's rmse: 3.62591 + 0.104124\n",
      "[980]\tcv_agg's rmse: 3.62491 + 0.104378\n",
      "[1000]\tcv_agg's rmse: 3.62403 + 0.104445\n",
      "[1020]\tcv_agg's rmse: 3.62344 + 0.104338\n",
      "[1040]\tcv_agg's rmse: 3.62294 + 0.104247\n",
      "[1060]\tcv_agg's rmse: 3.62237 + 0.104267\n",
      "[1080]\tcv_agg's rmse: 3.62182 + 0.104374\n",
      "[1100]\tcv_agg's rmse: 3.62116 + 0.104388\n",
      "[1120]\tcv_agg's rmse: 3.62075 + 0.104228\n",
      "[1140]\tcv_agg's rmse: 3.62013 + 0.104232\n",
      "[1160]\tcv_agg's rmse: 3.61977 + 0.104242\n",
      "[1180]\tcv_agg's rmse: 3.61936 + 0.104281\n",
      "[1200]\tcv_agg's rmse: 3.61897 + 0.104179\n",
      "[1220]\tcv_agg's rmse: 3.61857 + 0.104223\n",
      "[1240]\tcv_agg's rmse: 3.61788 + 0.104408\n",
      "[1260]\tcv_agg's rmse: 3.61759 + 0.104604\n",
      "[1280]\tcv_agg's rmse: 3.61724 + 0.104807\n",
      "[1300]\tcv_agg's rmse: 3.61679 + 0.10484\n",
      "[1320]\tcv_agg's rmse: 3.61633 + 0.105039\n",
      "[1340]\tcv_agg's rmse: 3.61586 + 0.10498\n",
      "[1360]\tcv_agg's rmse: 3.61543 + 0.104917\n",
      "[1380]\tcv_agg's rmse: 3.6151 + 0.104875\n",
      "[1400]\tcv_agg's rmse: 3.61479 + 0.104575\n",
      "[1420]\tcv_agg's rmse: 3.61429 + 0.104705\n",
      "[1440]\tcv_agg's rmse: 3.61389 + 0.104616\n",
      "[1460]\tcv_agg's rmse: 3.6136 + 0.104389\n",
      "[1480]\tcv_agg's rmse: 3.61361 + 0.104803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dhruv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Light GBM is  3.5747546735970523\n"
     ]
    }
   ],
   "source": [
    "#Running LightGBM with CrossValidation and Comparing the RMSE value for the predictions\n",
    "\n",
    "num_round=5000\n",
    "cv_results = lgb.cv(param, train_data, num_boost_round=num_round, nfold=10,verbose_eval=20, early_stopping_rounds=20,stratified=False)\n",
    "lgb_bst=lgb.train(param,train_data,len(cv_results['rmse-mean']))\n",
    "lgb_pred = lgb_bst.predict(X_test)\n",
    "lgb_rmse=np.sqrt(mean_squared_error(lgb_pred, y_test))\n",
    "print(\"RMSE for Light GBM is \",lgb_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tcv_agg's rmse: 4.37248 + 0.0963056\n",
      "[40]\tcv_agg's rmse: 3.99978 + 0.0993363\n",
      "[60]\tcv_agg's rmse: 3.89768 + 0.100983\n",
      "[80]\tcv_agg's rmse: 3.85548 + 0.101451\n",
      "[100]\tcv_agg's rmse: 3.82042 + 0.101236\n",
      "[120]\tcv_agg's rmse: 3.78958 + 0.102016\n",
      "[140]\tcv_agg's rmse: 3.76647 + 0.102975\n",
      "[160]\tcv_agg's rmse: 3.74707 + 0.103009\n",
      "[180]\tcv_agg's rmse: 3.7352 + 0.1035\n",
      "[200]\tcv_agg's rmse: 3.72391 + 0.102624\n",
      "[220]\tcv_agg's rmse: 3.71588 + 0.102788\n",
      "[240]\tcv_agg's rmse: 3.70665 + 0.10304\n",
      "[260]\tcv_agg's rmse: 3.69667 + 0.103073\n",
      "[280]\tcv_agg's rmse: 3.68687 + 0.103331\n",
      "[300]\tcv_agg's rmse: 3.68043 + 0.103441\n",
      "[320]\tcv_agg's rmse: 3.67184 + 0.104453\n",
      "[340]\tcv_agg's rmse: 3.66667 + 0.104766\n",
      "[360]\tcv_agg's rmse: 3.6632 + 0.104928\n",
      "[380]\tcv_agg's rmse: 3.65799 + 0.105286\n",
      "[400]\tcv_agg's rmse: 3.65509 + 0.105476\n",
      "[420]\tcv_agg's rmse: 3.65188 + 0.105649\n",
      "[440]\tcv_agg's rmse: 3.64933 + 0.105598\n",
      "[460]\tcv_agg's rmse: 3.64706 + 0.10568\n",
      "[480]\tcv_agg's rmse: 3.64513 + 0.105509\n",
      "[500]\tcv_agg's rmse: 3.64314 + 0.105349\n",
      "[520]\tcv_agg's rmse: 3.64145 + 0.105661\n",
      "[540]\tcv_agg's rmse: 3.63945 + 0.105811\n",
      "[560]\tcv_agg's rmse: 3.63778 + 0.105618\n",
      "[580]\tcv_agg's rmse: 3.63627 + 0.10585\n",
      "[600]\tcv_agg's rmse: 3.63465 + 0.105964\n",
      "[620]\tcv_agg's rmse: 3.63344 + 0.106138\n",
      "[640]\tcv_agg's rmse: 3.63145 + 0.106194\n",
      "[660]\tcv_agg's rmse: 3.6293 + 0.106305\n",
      "[680]\tcv_agg's rmse: 3.6281 + 0.10626\n",
      "[700]\tcv_agg's rmse: 3.62713 + 0.106417\n",
      "[720]\tcv_agg's rmse: 3.62662 + 0.106324\n",
      "[740]\tcv_agg's rmse: 3.62561 + 0.106114\n",
      "[760]\tcv_agg's rmse: 3.62431 + 0.105952\n",
      "[780]\tcv_agg's rmse: 3.6234 + 0.106028\n",
      "[800]\tcv_agg's rmse: 3.62248 + 0.1058\n",
      "[820]\tcv_agg's rmse: 3.62103 + 0.105805\n",
      "[840]\tcv_agg's rmse: 3.61986 + 0.10582\n",
      "[860]\tcv_agg's rmse: 3.61942 + 0.105812\n",
      "[880]\tcv_agg's rmse: 3.61878 + 0.105836\n",
      "[900]\tcv_agg's rmse: 3.61847 + 0.105931\n",
      "[920]\tcv_agg's rmse: 3.61784 + 0.106045\n",
      "[940]\tcv_agg's rmse: 3.61737 + 0.105973\n",
      "[960]\tcv_agg's rmse: 3.6167 + 0.106035\n",
      "[980]\tcv_agg's rmse: 3.61628 + 0.105937\n",
      "[1000]\tcv_agg's rmse: 3.61543 + 0.106193\n",
      "[1020]\tcv_agg's rmse: 3.61491 + 0.106286\n",
      "[1040]\tcv_agg's rmse: 3.61449 + 0.106266\n",
      "[1060]\tcv_agg's rmse: 3.61374 + 0.106377\n",
      "[1080]\tcv_agg's rmse: 3.61364 + 0.106285\n",
      "[1100]\tcv_agg's rmse: 3.61335 + 0.106261\n",
      "[1120]\tcv_agg's rmse: 3.61272 + 0.106392\n",
      "[1140]\tcv_agg's rmse: 3.61247 + 0.10632\n",
      "[1160]\tcv_agg's rmse: 3.61189 + 0.106235\n",
      "[1180]\tcv_agg's rmse: 3.61172 + 0.106254\n",
      "[1200]\tcv_agg's rmse: 3.61152 + 0.10626\n",
      "[1220]\tcv_agg's rmse: 3.61132 + 0.106185\n",
      "[1240]\tcv_agg's rmse: 3.61088 + 0.106041\n",
      "[1260]\tcv_agg's rmse: 3.61051 + 0.106043\n",
      "[1280]\tcv_agg's rmse: 3.61 + 0.106214\n",
      "[1300]\tcv_agg's rmse: 3.6097 + 0.106162\n",
      "[1320]\tcv_agg's rmse: 3.60944 + 0.106265\n",
      "[1340]\tcv_agg's rmse: 3.60925 + 0.106208\n",
      "[1360]\tcv_agg's rmse: 3.60902 + 0.106253\n",
      "[1380]\tcv_agg's rmse: 3.60901 + 0.106181\n",
      "[1400]\tcv_agg's rmse: 3.60859 + 0.106141\n",
      "[1420]\tcv_agg's rmse: 3.60848 + 0.106076\n",
      "[1440]\tcv_agg's rmse: 3.60833 + 0.10598\n",
      "[1460]\tcv_agg's rmse: 3.60847 + 0.105969\n",
      "RMSE for Light GBM is  3.5722381264264578\n"
     ]
    }
   ],
   "source": [
    "#Improving LightGBM Model by adding more tuning parameters \n",
    "\n",
    "param = {\n",
    "    'objective' : 'regression',\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'bagging_freq' : 20,\n",
    "    'subsample_frequency' : 100,\n",
    "    'num_leaves':100,\n",
    "    'min_data_in_leaf': 50, \n",
    "    'max_depth':8,\n",
    "    'colsample_bytree':0.5, \n",
    "    'lambda_l1':1,\n",
    "    'lambda_l2':0   \n",
    "}\n",
    "\n",
    "cv_results = lgb.cv(param, train_data, num_boost_round=num_round, nfold=10,verbose_eval=20, early_stopping_rounds=20,stratified=False)\n",
    "lgb_bst=lgb.train(param,train_data,len(cv_results['rmse-mean']))\n",
    "lgb_pred = lgb_bst.predict(X_test)\n",
    "lgb_rmse=np.sqrt(mean_squared_error(lgb_pred, y_test))\n",
    "print(\"RMSE for Light GBM is \",lgb_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Light GBM is  3.473198503479004\n"
     ]
    }
   ],
   "source": [
    "#Building LightGBM model with more tuning parameters \n",
    "\n",
    "param = {\n",
    "        'boosting_type':'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'nthread': 4,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': -1,\n",
    "        'subsample': 0.8,\n",
    "        'bagging_fraction' : 1,\n",
    "        'max_bin' : 5000 ,\n",
    "        'bagging_freq': 20,\n",
    "        'colsample_bytree': 0.6,\n",
    "        'metric': 'rmse',\n",
    "        'min_split_gain': 0.5,\n",
    "        'min_child_weight': 1,\n",
    "        'min_child_samples': 10,\n",
    "        'scale_pos_weight':1,\n",
    "        'zero_as_missing': True,\n",
    "        'seed':0,\n",
    "        'num_rounds':50000\n",
    "    }\n",
    "\n",
    "lgb_bst=lgb.train(param,train_data,num_boost_round=10000,verbose_eval=500)\n",
    "lgb_pred = lgb_bst.predict(X_test)\n",
    "lgb_rmse=np.sqrt(mean_squared_error(lgb_pred, y_test))\n",
    "print(\"RMSE for Light GBM is \",lgb_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dhruv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7, 'lambda_l1': 1, 'lambda_l2': 0, 'max_depth': 15}\n",
      "0.8412823564351186\n"
     ]
    }
   ],
   "source": [
    "#Using GridSearchCV to find the optimal tuning parameters for the LightGBM model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_params = { \n",
    "    'max_depth':[5, 15, 30],\n",
    "    'colsample_bytree':[0.3, 0.7], \n",
    "    'lambda_l1':[0, 1, 1.5],\n",
    "    'lambda_l2':[0, 1]    \n",
    "}\n",
    "\n",
    "lgb_reg = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    n_jobs = -1,\n",
    "    verbose = 1, \n",
    "    boosting_type = 'gbdt',\n",
    "    num_leaves = 31,\n",
    "    bagging_freq = 20,\n",
    "    max_depth = 5,\n",
    "    colsample_bytree = 0.3,\n",
    "    min_data_in_leaf = 30,\n",
    "    lambda_l1 = 0,\n",
    "    lambda_l2 = 0)\n",
    "\n",
    "lgb_reg.get_params().keys()\n",
    "\n",
    "\n",
    "grid = GridSearchCV(lgb_reg, grid_params)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dhruv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Light GBM is  3.4710864718957914\n"
     ]
    }
   ],
   "source": [
    "#Building LightGBM model with optimal tuning parameters found using GridSearchCV\n",
    "\n",
    "param = {\n",
    "        'boosting_type':'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'nthread': 4,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 15,\n",
    "        'subsample': 0.8,\n",
    "        'bagging_fraction' : 1,\n",
    "        'max_bin' : 5000 ,\n",
    "        'bagging_freq': 20,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'metric': 'rmse',\n",
    "        'min_split_gain': 0.5,\n",
    "        'min_child_weight': 1,\n",
    "        'min_child_samples': 10,\n",
    "        'scale_pos_weight':1,\n",
    "        'zero_as_missing': True,\n",
    "        'seed':0,\n",
    "        'num_rounds':50000,\n",
    "        'lambda_l1': 1,\n",
    "        'lambda_l2': 0\n",
    "    }\n",
    "\n",
    "lgb_bst=lgb.train(param,train_data,num_boost_round=10000,verbose_eval=500)\n",
    "lgb_pred = lgb_bst.predict(X_test)\n",
    "lgb_rmse=np.sqrt(mean_squared_error(lgb_pred, y_test))\n",
    "print(\"RMSE for Light GBM is \",lgb_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.27342703,  8.4309459 , 30.63615465, ...,  4.73294701,\n",
       "       17.3961679 ,  4.9889011 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"C:/Users/dhruv/Machine Learning/cleaned_test_data.csv\", usecols = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lgb_bst.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.33529451, 10.71883571,  3.99542776, ..., 53.31700581,\n",
       "       17.72180397,  6.69142548])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_keys = pd.read_csv(\"C:/Users/dhruv/Machine Learning/cleaned_test_data.csv\", usecols = [\"key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.33529451, 10.71883571,  3.99542776, ..., 53.31700581,\n",
       "       17.72180397,  6.69142548])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_prediction = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_prediction['key']=test_data_keys['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_prediction['fare_amount'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_prediction.to_csv(\"predictions.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
